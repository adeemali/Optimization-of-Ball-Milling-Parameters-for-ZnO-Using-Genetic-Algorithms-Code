#complete with 6 algorithms

#  STEP 1: Install required libraries
#!pip install deap matplotlib scikit-learn pandas numpy --quiet

# STEP 2: Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
from deap import base, creator, tools, algorithms
import warnings
warnings.filterwarnings("ignore")

#  STEP 3: Define dataset
data = [
    [400, 2, 100, 1, None, 0.1, "Zirconia", "Dry", None, 9.51],
    [250, 1200, 30, 10, 30, None, "Tungsten carbide", "Wet", 69.43, 13.07],
    [300, 2, 15, 15, 5, 10, "Steel", "Dry", None, 22],
    [300, 15, 20, 6, None, None, "Stainless-steel", "Dry", 240, 26],
    [300, 2, 10, 20, 15, None, "Chromium steel", "Dry", None, 15],
    [100, 5, None, 1, None, 5, "Zirconia", "Dry", 25, 22],
    [300, 3000, 100, 2, None, None, "Stainless Steel", "Dry", None, 15]
]
columns = [
    "Rotation_speed", "Milling_time", "Ball_to_powder_ratio", "Ball_diameter",
    "Number_of_balls", "Precursor_amount", "Ball_material", "Milling_atmosphere",
    "Initial_crystallite_size", "Final_crystallite_size"
]
df = pd.DataFrame(data, columns=columns)

#  STEP 4: Preprocess
df["Ball_material_encoded"] = df["Ball_material"].astype("category").cat.codes
df["Milling_atmosphere_encoded"] = df["Milling_atmosphere"].map({"Dry": 0, "Wet": 1})
df_clean = df.drop(columns=["Ball_material", "Milling_atmosphere", "Initial_crystallite_size"])
df_clean = df_clean.dropna(subset=["Final_crystallite_size"])
df_clean = df_clean.fillna(df_clean.median(numeric_only=True))

X = df_clean.drop(columns=["Final_crystallite_size"])
y = df_clean["Final_crystallite_size"]

scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

#  STEP 5: Train Regression Model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_scaled, y)

#  STEP 6: Evaluate Model
y_pred = model.predict(X_scaled)
mae = mean_absolute_error(y, y_pred)
r2 = r2_score(y, y_pred)
print(f"\nðŸ“Š Model Evaluation:\nMAE = {mae:.3f}, RÂ² = {r2:.3f}\n")

#  Feature Importance Plot
importances = model.feature_importances_
plt.figure(figsize=(10, 6))
plt.barh(X.columns, importances)
plt.title("Feature Importance (Random Forest)")
plt.xlabel("Importance")
plt.grid(True)
plt.tight_layout()
plt.show()

#  STEP 7: Setup Genetic Algorithm
from collections import defaultdict
creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
creator.create("Individual", list, fitness=creator.FitnessMin)
toolbox = base.Toolbox()

bounds = [
    (100, 600),     # Rotation_speed
    (1, 3000),      # Milling_time
    (10, 100),      # Ball_to_powder_ratio
    (1, 20),        # Ball_diameter
    (1, 50),        # Number_of_balls
    (0.01, 10),     # Precursor_amount
    (0, 4),         # Ball_material_encoded
    (0, 1)          # Milling_atmosphere_encoded
]
def random_within_bounds(min_val, max_val):
    return np.random.uniform(min_val, max_val)
toolbox.register("individual", tools.initCycle, creator.Individual,
                 [lambda lo=lo, hi=hi: random_within_bounds(lo, hi) for lo, hi in bounds], n=1)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)

def eval_crystallite(individual):
    clipped = [np.clip(individual[i], bounds[i][0], bounds[i][1]) for i in range(len(individual))]
    clipped[4] = int(round(clipped[4]))
    clipped[6] = int(round(clipped[6]))
    clipped[7] = int(round(clipped[7]))
    input_scaled = scaler.transform([clipped])
    prediction = model.predict(input_scaled)[0]
    return (prediction,)

toolbox.register("evaluate", eval_crystallite)
toolbox.register("mate", tools.cxBlend, alpha=0.5)
toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=0.2, indpb=0.2)
toolbox.register("select", tools.selTournament, tournsize=3)

# ---------- GA Variants and Tracking ----------
ga_results = {}
ga_convergence = {}

# ManualGA with parameter evolution tracking
def run_manual_ga():
    num_generations = 40
    pop = toolbox.population(n=30)
    hof = tools.HallOfFame(1)
    min_fit, avg_fit = [], []
    best_param_evolution = []
    for gen in range(num_generations):
        offspring = algorithms.varAnd(pop, toolbox, cxpb=0.5, mutpb=0.3)
        fits = list(map(toolbox.evaluate, offspring))
        for fit_val, ind in zip(fits, offspring):
            ind.fitness.values = fit_val
        pop = toolbox.select(offspring, k=len(pop))
        hof.update(pop)
        fitness_vals = [ind.fitness.values[0] for ind in pop]
        min_fit.append(np.min(fitness_vals))
        avg_fit.append(np.mean(fitness_vals))
        # Track best individual's parameters this generation
        best_ind = tools.selBest(pop, 1)[0]
        clipped = [np.clip(best_ind[i], bounds[i][0], bounds[i][1]) for i in range(len(best_ind))]
        clipped[4] = int(round(clipped[4]))
        clipped[6] = int(round(clipped[6]))
        clipped[7] = int(round(clipped[7]))
        best_param_evolution.append(clipped)
    return hof, min_fit, avg_fit, np.array(best_param_evolution)

hof_manual, min_fit_manual, avg_fit_manual, param_evolution_manual = run_manual_ga()
ga_results["ManualGA"] = hof_manual[0]
ga_convergence["ManualGA"] = min_fit_manual

# Other GAs with tracking
def run_ga_with_param_tracking(algo_fn, **algo_kwargs):
    pop = toolbox.population(n=30)
    hof = tools.HallOfFame(1)
    min_fit = []
    param_evolution = []

    # Evaluate initial population
    fitnesses = list(map(toolbox.evaluate, pop))
    for ind, fit in zip(pop, fitnesses):
        ind.fitness.values = fit

    # Record initial best
    def record_best(pop):
        best_ind = tools.selBest(pop, 1)[0]
        clipped = [np.clip(best_ind[i], bounds[i][0], bounds[i][1]) for i in range(len(best_ind))]
        clipped[4] = int(round(clipped[4]))
        clipped[6] = int(round(clipped[6]))
        clipped[7] = int(round(clipped[7]))
        param_evolution.append(clipped)
        min_fit.append(best_ind.fitness.values[0])

    record_best(pop)
    ngen = 40

    for gen in range(ngen):
        # Variation
        if algo_fn == algorithms.eaSimple:
            offspring = algorithms.varAnd(pop, toolbox, cxpb=0.5, mutpb=0.3)
            fits = list(map(toolbox.evaluate, offspring))
            for fit_val, ind in zip(fits, offspring):
                ind.fitness.values = fit_val
            pop = toolbox.select(offspring, k=len(pop))
        elif algo_fn == algorithms.eaGenerateUpdate:
            offspring = list(map(toolbox.clone, pop))
            offspring = algorithms.varOr(offspring, toolbox, lambda_=30, cxpb=0.5, mutpb=0.3)
            fits = list(map(toolbox.evaluate, offspring))
            for fit_val, ind in zip(fits, offspring):
                ind.fitness.values = fit_val
            pop[:] = offspring
        else:
            offspring = algorithms.varOr(pop, toolbox, lambda_=60, cxpb=0.5, mutpb=0.3)
            fits = list(map(toolbox.evaluate, offspring))
            for fit_val, ind in zip(fits, offspring):
                ind.fitness.values = fit_val
            if algo_fn == algorithms.eaMuPlusLambda:
                pop = toolbox.select(pop + offspring, k=len(pop))
            elif algo_fn == algorithms.eaMuCommaLambda:
                pop = toolbox.select(offspring, k=len(pop))
        hof.update(pop)
        record_best(pop)

    return hof, min_fit, np.array(param_evolution)

# Run all variants
hof_simple, min_fit_simple, param_evolution_simple = run_ga_with_param_tracking(algorithms.eaSimple)
hof_mupl, min_fit_mupl, param_evolution_mupl = run_ga_with_param_tracking(algorithms.eaMuPlusLambda)
hof_mucl, min_fit_mucl, param_evolution_mucl = run_ga_with_param_tracking(algorithms.eaMuCommaLambda)
hof_genupd1, min_fit_genupd1, param_evolution_genupd1 = run_ga_with_param_tracking(algorithms.eaGenerateUpdate)
# For 6th GA: Change parameters as an example (e.g., more generations or population)
def run_eaGenerateUpdate2():
    pop = toolbox.population(n=30)
    hof = tools.HallOfFame(1)
    min_fit = []
    param_evolution = []

    # Evaluate initial population
    fitnesses = list(map(toolbox.evaluate, pop))
    for ind, fit in zip(pop, fitnesses):
        ind.fitness.values = fit

    def record_best(pop):
        best_ind = tools.selBest(pop, 1)[0]
        clipped = [np.clip(best_ind[i], bounds[i][0], bounds[i][1]) for i in range(len(best_ind))]
        clipped[4] = int(round(clipped[4]))
        clipped[6] = int(round(clipped[6]))
        clipped[7] = int(round(clipped[7]))
        param_evolution.append(clipped)
        min_fit.append(best_ind.fitness.values[0])

    record_best(pop)
    ngen = 40
    for gen in range(ngen):
        offspring = list(map(toolbox.clone, pop))
        offspring = algorithms.varOr(offspring, toolbox, lambda_=60, cxpb=0.5, mutpb=0.3)
        fits = list(map(toolbox.evaluate, offspring))
        for fit_val, ind in zip(fits, offspring):
            ind.fitness.values = fit_val
        pop[:] = offspring
        hof.update(pop)
        record_best(pop)

    return hof, min_fit, np.array(param_evolution)

hof_genupd2, min_fit_genupd2, param_evolution_genupd2 = run_eaGenerateUpdate2()

# Add to results/convergence
ga_results["eaSimple"] = hof_simple[0]
ga_results["eaMuPlusLambda"] = hof_mupl[0]
ga_results["eaMuCommaLambda"] = hof_mucl[0]
ga_results["eaGenerateUpdate"] = hof_genupd1[0]
ga_results["eaGenerateUpdate2"] = hof_genupd2[0]

ga_convergence["eaSimple"] = min_fit_simple
ga_convergence["eaMuPlusLambda"] = min_fit_mupl
ga_convergence["eaMuCommaLambda"] = min_fit_mucl
ga_convergence["eaGenerateUpdate"] = min_fit_genupd1
ga_convergence["eaGenerateUpdate2"] = min_fit_genupd2

# ---------- Compare Results ----------
param_names = [
    "Rotation Speed", "Milling Time", "Ball:Powder Ratio", "Ball Diameter",
    "Number of Balls", "Precursor Amount", "Ball Material (Encoded)", "Milling Atmosphere (0=Dry,1=Wet)"
]
final_results = []
for label, ind in ga_results.items():
    clipped = [np.clip(ind[i], bounds[i][0], bounds[i][1]) for i in range(len(ind))]
    clipped[4] = int(round(clipped[4]))
    clipped[6] = int(round(clipped[6]))
    clipped[7] = int(round(clipped[7]))
    best_scaled = scaler.transform([clipped])[0]
    best_prediction = model.predict([best_scaled])[0]
    final_results.append([label] + clipped + [best_prediction])

results_df = pd.DataFrame(final_results, columns=["GA Variant"] + param_names + ["Predicted Final Crystallite Size"])
print("\nðŸ“‹ Comparison of GA Variants:")
print(results_df)

# Plot convergence
plt.figure(figsize=(10, 6))
for label, min_fit in ga_convergence.items():
    plt.plot(min_fit, label=label)
plt.xlabel("Generation")
plt.ylabel("Best Fitness (Predicted Crystallite Size)")
plt.title("GA Variant Convergence Comparison")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Plot convergence for all six GAs
ga_labels = [
    "ManualGA", "eaSimple", "eaMuPlusLambda",
    "eaMuCommaLambda", "eaGenerateUpdate", "eaGenerateUpdate2"
]
min_fit_lists = [
    min_fit_manual, min_fit_simple, min_fit_mupl,
    min_fit_mucl, min_fit_genupd1, min_fit_genupd2
]

plt.figure(figsize=(18, 10))
for i, (label, min_fit) in enumerate(zip(ga_labels, min_fit_lists), 1):
    plt.subplot(2, 3, i)
    plt.plot(range(1, len(min_fit) + 1), min_fit, marker='o', linestyle='-')
    plt.xlabel("Generation")
    plt.ylabel("Best Fitness")
    plt.title(f"{label}: Optimization Progress")
    plt.grid(True)
    plt.tight_layout()
plt.suptitle("Optimization Progress per Generation for Each GA Variant", fontsize=16, y=1.02)
plt.show()

# Plot evolution of best parameters for all six GAs
param_evolutions = [
    ("ManualGA", param_evolution_manual),
    ("eaSimple", param_evolution_simple),
    ("eaMuPlusLambda", param_evolution_mupl),
    ("eaMuCommaLambda", param_evolution_mucl),
    ("eaGenerateUpdate", param_evolution_genupd1),
    ("eaGenerateUpdate2", param_evolution_genupd2),
]
fig, axes = plt.subplots(2, 3, figsize=(24, 12), sharex=True)
for ax, (label, evolution) in zip(axes.flatten(), param_evolutions):
    for i, pname in enumerate(param_names):
        ax.plot(range(1, evolution.shape[0] + 1), evolution[:, i], label=pname)
    ax.set_title(f"{label} - Best Parameters Over Generations", fontsize=14)
    ax.set_xlabel("Generation")
    ax.set_ylabel("Parameter Value")
    ax.grid(True)
    if label == "ManualGA":  # Show legend only on first plot to avoid clutter
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)
plt.tight_layout()
plt.suptitle("Evolution of Best Parameters Over Generations (All GA Variants)", fontsize=18, y=1.05)
plt.show()
